{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1b5c23dd",
   "metadata": {},
   "source": [
    "# Chapter 4: Mess Management with Documents\n",
    "\n",
    "\n",
    ">This notebook is based on the open-source project [wow-rag](https://github.com/datawhalechina/wow-rag) by Datawhale China.  \n",
    ">I’ve adapted and annotated parts of it for personal learning and experimentation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd2223c3",
   "metadata": {},
   "source": [
    "## 1. Introduction \n",
    "\n",
    "Before we can retrieve answers or build intelligent applications, we need to ensure that our document data is well-managed. This chapter focuses on the often-overlooked but essential tasks of **document ingestion**, **inspection**, and **modification** using `LlamaIndex`. Whether we're inserting new data, examining existing nodes, or attempting tricky operations like deletion and updates, understanding how your index handles documents and nodes is critical.\n",
    "\n",
    "We’ll explore how to:\n",
    "\n",
    "- View and inspect stored documents and their internal node structures.\n",
    "\n",
    "- Add new nodes or re-ingest documents using transformation pipelines.\n",
    "\n",
    "- Handle updates by replacing outdated nodes (since direct modification isn’t supported).\n",
    "\n",
    "- Avoid common pitfalls—like accidental deletion—that can break your pipeline.\n",
    "\n",
    "Let’s roll up our sleeves and bring order to the mess. \n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "> ⚠️ **Warning: Real-World Document Management is Harder Than It Looks**\n",
    "\n",
    "While this tutorial uses a **highly simplified dataset and workflow**, real-world RAG projects are far more demanding. \n",
    "\n",
    "In production, **document management can consume up to 80% of the total project effort**. This includes not only indexing, but also data cleaning, transformation, and retrieval optimization.\n",
    "\n",
    "Here’s what makes document management so challenging in practice:\n",
    "\n",
    "###  1. Complex Document Formats\n",
    "- Input data may come from PDFs, Word files, scanned images, websites, or databases.\n",
    "- Some require OCR or DOM parsing, which adds complexity.\n",
    "\n",
    "###  2. Smart Chunking is Critical\n",
    "- Chunk size and overlap must balance **context preservation** with **embedding efficiency**.\n",
    "- Poor chunking leads to semantic drift and irrelevant retrieval results.\n",
    "- In Chinese (or multilingual) documents, sentence segmentation is even more difficult.\n",
    "\n",
    "###  3. Embedding Quality Drives Results\n",
    "- Choosing the right embedding model (e.g., BGE, m3e, text2vec) is crucial.\n",
    "- Inclusion of metadata (title, section headers) often improves semantic clarity.\n",
    "- Embedding must be re-run if chunks are updated or tokenized differently.\n",
    "\n",
    "###  4. Indexing & Metadata Management\n",
    "- Storing and querying metadata (e.g., tags, dates, authors) alongside vectors is essential.\n",
    "- Indexing strategies (like FAISS, Qdrant, Chroma) vary in scalability, update support, and performance.\n",
    "\n",
    "###  5. Updates and Deletions Are Non-Trivial\n",
    "- There is **no direct in-place editing** of indexed nodes.\n",
    "- You must **track document IDs** and **replace or rebuild** affected chunks carefully.\n",
    "\n",
    "###  6. Inspection and Debugging Are Time-Consuming\n",
    "- You’ll often need to **inspect individual nodes**, verify embeddings, or simulate retrieval results manually.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1576b3",
   "metadata": {},
   "source": [
    "## 2. Preparation\n",
    "\n",
    "Same as always, use `example.txt` as the document source, and adopt **Method 1 from Chapter 3** — the simplest way to build a semantic index directly from documents using VectorStoreIndex. This approach is ideal for rapid prototyping or small-scale testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8996a692",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv('API_KEY')\n",
    "\n",
    "base_url = \"https://api.openai.com/v1\"  \n",
    "chat_model = \"gpt-4.1-nano-2025-04-14\"   \n",
    "emb_model = \"text-embedding-3-small\"\n",
    "\n",
    "\n",
    "from llama_index.llms.openai import OpenAI\n",
    "llm = OpenAI(\n",
    "    api_key = api_key,\n",
    "    model = chat_model,\n",
    ")\n",
    "\n",
    "\n",
    "from llama_index.embeddings.openai import OpenAIEmbedding\n",
    "embedding = OpenAIEmbedding(\n",
    "    api_key = api_key,\n",
    "    model = emb_model,\n",
    ")\n",
    "emb = embedding.get_text_embedding(\"Hello\")\n",
    "\n",
    "#Method 1 in Ch3\n",
    "\n",
    "from llama_index.core import SimpleDirectoryReader,Document\n",
    "documents = SimpleDirectoryReader(input_files=['./docs/example.txt']).load_data()\n",
    "\n",
    "from llama_index.core import VectorStoreIndex\n",
    "index = VectorStoreIndex.from_documents(documents,embed_model=embedding)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13f2a53c",
   "metadata": {},
   "source": [
    "## 3. Knowing the Index Internals\n",
    "\n",
    "This subsection helps us understand what happens behind the scenes after building an index. Specifically:\n",
    "\n",
    "- `index.docstore.docs` shows all the stored nodes (chunks of your documents).\n",
    "\n",
    "- `index.index_struct.nodes_dict` maps internal node IDs for quick lookup.\n",
    "\n",
    "- `index.ref_doc`_info shows document-level metadata and references.\n",
    "\n",
    "- `get_node()` lets us retrieve and inspect a specific indexed chunk by its ID.\n",
    "\n",
    "Together, these let us verify:\n",
    "\n",
    "- How many chunks were created from our document,\n",
    "\n",
    "- What metadata is attached,\n",
    "\n",
    "- How the document and node IDs are tracked.\n",
    "\n",
    "This step is useful for debugging, transparency, and gaining confidence in the structure before we perform queries or apply filters.\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f60914a",
   "metadata": {},
   "source": [
    "### 3.1 View all documents under index\n",
    "\n",
    "It's a dictionary that maps **Node ID** to its corresponding `TextNod` object.   \n",
    "\n",
    "Each `TextNode` contains the chunked content, metadata, and optionally embedding info."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6fd3d5c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'e1ab309c-8f22-4900-bd46-b740b8a5fc5e': TextNode(id_='e1ab309c-8f22-4900-bd46-b740b8a5fc5e', embedding=None, metadata={'file_path': 'docs\\\\example.txt', 'file_name': 'example.txt', 'file_type': 'text/plain', 'file_size': 3355, 'creation_date': '2025-07-19', 'last_modified_date': '2025-07-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='bf6c6d9b-81cf-4370-a9df-5f97304fbcaa', node_type='4', metadata={'file_path': 'docs\\\\example.txt', 'file_name': 'example.txt', 'file_type': 'text/plain', 'file_size': 3355, 'creation_date': '2025-07-19', 'last_modified_date': '2025-07-19'}, hash='a2b68e6316c64e022863136a58cae33d2dc26e9576e335f9ae1d8007a21aba56')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Multimodal Agent AI systems have many applications. In addition to interactive AI, grounded multimodal models could help drive content generation for bots and AI agents, and assist in productivity applications, helping to re-play, paraphrase, action prediction or synthesize 3D or 2D scenario. Fundamental advances in agent AI help contribute towards these goals and many would benefit from a greater understanding of how to model embodied and empathetic in a simulate reality or a real world. Arguably many of these applications could have positive benefits.\\r\\n\\r\\nHowever, this technology could also be used by bad actors. Agent AI systems that generate content can be used to manipulate or deceive people. Therefore, it is very important that this technology is developed in accordance with responsible AI guidelines. For example, explicitly communicating to users that content is generated by an AI system and providing the user with controls in order to customize such a system. It is possible the Agent AI could be used to develop new methods to detect manipulative content - partly because it is rich with hallucination performance of large foundation model - and thus help address another real world problem.\\r\\n\\r\\nFor examples, 1) in health topic, ethical deployment of LLM and VLM agents, especially in sensitive domains like healthcare, is paramount. AI agents trained on biased data could potentially worsen health disparities by providing inaccurate diagnoses for underrepresented groups. Moreover, the handling of sensitive patient data by AI agents raises significant privacy and confidentiality concerns. 2) In the gaming industry, AI agents could transform the role of developers, shifting their focus from scripting non-player characters to refining agent learning processes. Similarly, adaptive robotic systems could redefine manufacturing roles, necessitating new skill sets rather than replacing human workers. Navigating these transitions responsibly is vital to minimize potential socio-economic disruptions.\\r\\n\\r\\nFurthermore, the agent AI focuses on learning collaboration policy in simulation and there is some risk if directly applying the policy to the real world due to the distribution shift. Robust testing and continual safety monitoring mechanisms should be put in place to minimize risks of unpredictable behaviors in real-world scenarios. Our “VideoAnalytica\" dataset is collected from the Internet and considering which is not a fully representative source, so we already go through-ed the ethical review and legal process from both Microsoft and University Washington. Be that as it may, we also need to understand biases that might exist in this corpus. Data distributions can be characterized in many ways. In this workshop, we have captured how the agent level distribution in our dataset is different from other existing datasets. However, there is much more than could be included in a single dataset or workshop. We would argue that there is a need for more approaches or discussion linked to real tasks or topics and that by making these data or system available.\\r\\n\\r\\nWe will dedicate a segment of our project to discussing these ethical issues, exploring potential mitigation strategies, and deploying a responsible multi-modal AI agent. We hope to help more researchers answer these questions together via this paper.', mimetype='text/plain', start_char_idx=0, end_char_idx=3353, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}')}\n"
     ]
    }
   ],
   "source": [
    "print(index.docstore.docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d142632e",
   "metadata": {},
   "source": [
    "### 3.2 View all node's id under index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "79890376",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'e1ab309c-8f22-4900-bd46-b740b8a5fc5e': 'e1ab309c-8f22-4900-bd46-b740b8a5fc5e'}\n"
     ]
    }
   ],
   "source": [
    "print(index.index_struct.nodes_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f5d856",
   "metadata": {},
   "source": [
    "**Why multiple nodes?**  \n",
    "\n",
    "LlamaIndex splits long documents into smaller parts to:\n",
    "\n",
    "Fit the token limit for embedding models (like OpenAI's text-embedding-3-small)\n",
    "\n",
    "```\n",
    "[ Example.txt ]\n",
    " ├── Chunk 1 → Node ID: ae2f75...\n",
    " ├── Chunk 2 → Node ID: adda4a...\n",
    " └── Chunk 3 → Node ID: e81b06..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01e227f8",
   "metadata": {},
   "source": [
    "### 3.3 View all documents ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b9ffdb90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'bf6c6d9b-81cf-4370-a9df-5f97304fbcaa': RefDocInfo(node_ids=['e1ab309c-8f22-4900-bd46-b740b8a5fc5e'], metadata={'file_path': 'docs\\\\example.txt', 'file_name': 'example.txt', 'file_type': 'text/plain', 'file_size': 3355, 'creation_date': '2025-07-19', 'last_modified_date': '2025-07-19'})}\n"
     ]
    }
   ],
   "source": [
    "print(index.ref_doc_info)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83e26999",
   "metadata": {},
   "source": [
    "### 3.4 View information about node with a given id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b6b78152",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TextNode(id_='e1ab309c-8f22-4900-bd46-b740b8a5fc5e', embedding=None, metadata={'file_path': 'docs\\\\example.txt', 'file_name': 'example.txt', 'file_type': 'text/plain', 'file_size': 3355, 'creation_date': '2025-07-19', 'last_modified_date': '2025-07-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='bf6c6d9b-81cf-4370-a9df-5f97304fbcaa', node_type='4', metadata={'file_path': 'docs\\\\example.txt', 'file_name': 'example.txt', 'file_type': 'text/plain', 'file_size': 3355, 'creation_date': '2025-07-19', 'last_modified_date': '2025-07-19'}, hash='a2b68e6316c64e022863136a58cae33d2dc26e9576e335f9ae1d8007a21aba56')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Multimodal Agent AI systems have many applications. In addition to interactive AI, grounded multimodal models could help drive content generation for bots and AI agents, and assist in productivity applications, helping to re-play, paraphrase, action prediction or synthesize 3D or 2D scenario. Fundamental advances in agent AI help contribute towards these goals and many would benefit from a greater understanding of how to model embodied and empathetic in a simulate reality or a real world. Arguably many of these applications could have positive benefits.\\r\\n\\r\\nHowever, this technology could also be used by bad actors. Agent AI systems that generate content can be used to manipulate or deceive people. Therefore, it is very important that this technology is developed in accordance with responsible AI guidelines. For example, explicitly communicating to users that content is generated by an AI system and providing the user with controls in order to customize such a system. It is possible the Agent AI could be used to develop new methods to detect manipulative content - partly because it is rich with hallucination performance of large foundation model - and thus help address another real world problem.\\r\\n\\r\\nFor examples, 1) in health topic, ethical deployment of LLM and VLM agents, especially in sensitive domains like healthcare, is paramount. AI agents trained on biased data could potentially worsen health disparities by providing inaccurate diagnoses for underrepresented groups. Moreover, the handling of sensitive patient data by AI agents raises significant privacy and confidentiality concerns. 2) In the gaming industry, AI agents could transform the role of developers, shifting their focus from scripting non-player characters to refining agent learning processes. Similarly, adaptive robotic systems could redefine manufacturing roles, necessitating new skill sets rather than replacing human workers. Navigating these transitions responsibly is vital to minimize potential socio-economic disruptions.\\r\\n\\r\\nFurthermore, the agent AI focuses on learning collaboration policy in simulation and there is some risk if directly applying the policy to the real world due to the distribution shift. Robust testing and continual safety monitoring mechanisms should be put in place to minimize risks of unpredictable behaviors in real-world scenarios. Our “VideoAnalytica\" dataset is collected from the Internet and considering which is not a fully representative source, so we already go through-ed the ethical review and legal process from both Microsoft and University Washington. Be that as it may, we also need to understand biases that might exist in this corpus. Data distributions can be characterized in many ways. In this workshop, we have captured how the agent level distribution in our dataset is different from other existing datasets. However, there is much more than could be included in a single dataset or workshop. We would argue that there is a need for more approaches or discussion linked to real tasks or topics and that by making these data or system available.\\r\\n\\r\\nWe will dedicate a segment of our project to discussing these ethical issues, exploring potential mitigation strategies, and deploying a responsible multi-modal AI agent. We hope to help more researchers answer these questions together via this paper.', mimetype='text/plain', start_char_idx=0, end_char_idx=3353, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.docstore.get_node('e1ab309c-8f22-4900-bd46-b740b8a5fc5e') # last step 's any id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565c20dc",
   "metadata": {},
   "source": [
    "## 4. Modifying Your Vector Index: Add & Delete Operations\n",
    "\n",
    "In this section, we explore how to manually update the vector index by either deleting a document or inserting new nodes.\n",
    "\n",
    "\n",
    "**⚠️ Avoid using the delete operation unless absolutely necessary.\n",
    "Improper deletion can lead to inconsistencies or runtime errors in later code blocks.**\n",
    "\n",
    "While adding new nodes can be useful during incremental updates, deletion might break relationships between nodes and cause the retriever or query engine to fail. For stable workflows, it’s usually better to rebuild the index from scratch when document changes are needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18940ea0",
   "metadata": {},
   "source": [
    "### 4.1 Delete Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad1e3215",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index.docstore.delete_document('51595901-ebe3-48b5-b57b-dc8794ef4556')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4afa6b3b",
   "metadata": {},
   "source": [
    "### 4.2 Add Node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b48ea0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# index.insert_nodes([doc_single])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96c212de",
   "metadata": {},
   "source": [
    "Note: `doc_single` must be a `TextNode` object, such as the one we saw earlier when viewing a node.  \n",
    "\n",
    "You can also construct a `TextNode` manually. Here's how:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42eaebfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.schema import TextNode\n",
    "nodes = [\n",
    "    TextNode(\n",
    "        text=\"The Shawshank Redemption\",\n",
    "        metadata={\n",
    "            \"author\": \"Stephen King\",\n",
    "            \"theme\": \"Friendship\",\n",
    "            \"year\": 1994,\n",
    "        },\n",
    "    ),\n",
    "    TextNode(\n",
    "        text=\"The Godfather\",\n",
    "        metadata={\n",
    "            \"director\": \"Francis Ford Coppola\",\n",
    "            \"theme\": \"Mafia\",\n",
    "            \"year\": 1972,\n",
    "        },\n",
    "    )\n",
    "]\n",
    "index.insert_nodes(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80476dfc",
   "metadata": {},
   "source": [
    "It's also possible to construct a `TextNode` object from a document like the last chapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f1c822d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[TextNode(id_='516c5101-798f-41e1-9332-fe8e96ca6383', embedding=None, metadata={'file_path': 'docs\\\\another_example.txt', 'file_name': 'another_example.txt', 'file_type': 'text/plain', 'file_size': 3355, 'creation_date': '2025-07-21', 'last_modified_date': '2025-07-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='5b853f0a-2fd0-4a35-a2e2-033f53e0acf6', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'file_path': 'docs\\\\another_example.txt', 'file_name': 'another_example.txt', 'file_type': 'text/plain', 'file_size': 3355, 'creation_date': '2025-07-21', 'last_modified_date': '2025-07-19'}, hash='e21b18d7025601f845c7287c1f5cfc20cbd20d88aabe3050302d7a9742561127'), <NodeRelationship.NEXT: '3'>: RelatedNodeInfo(node_id='612430ac-db61-464b-ab87-499b94a6022f', node_type=<ObjectType.TEXT: '1'>, metadata={}, hash='5128f538caf583931f5dcc7bd0d013dd356a78f5eaf21fb9dae1dba236603900')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='Multimodal Agent AI systems have many applications. In addition to interactive AI, grounded multimodal models could help drive content generation for bots and AI agents, and assist in productivity applications, helping to re-play, paraphrase, action prediction or synthesize 3D or 2D scenario. Fundamental advances in agent AI help contribute towards these goals and many would benefit from a greater understanding of how to model embodied and empathetic in a simulate reality or a real world. Arguably many of these applications could have positive benefits.\\r\\n\\r\\nHowever, this technology could also be used by bad actors. Agent AI systems that generate content can be used to manipulate or deceive people. Therefore, it is very important that this technology is developed in accordance with responsible AI guidelines. For example, explicitly communicating to users that content is generated by an AI system and providing the user with controls in order to customize such a system. It is possible the Agent AI could be used to develop new methods to detect manipulative content - partly because it is rich with hallucination performance of large foundation model - and thus help address another real world problem.\\r\\n\\r\\nFor examples, 1) in health topic, ethical deployment of LLM and VLM agents, especially in sensitive domains like healthcare, is paramount. AI agents trained on biased data could potentially worsen health disparities by providing inaccurate diagnoses for underrepresented groups. Moreover, the handling of sensitive patient data by AI agents raises significant privacy and confidentiality concerns. 2) In the gaming industry, AI agents could transform the role of developers, shifting their focus from scripting non-player characters to refining agent learning processes. Similarly, adaptive robotic systems could redefine manufacturing roles, necessitating new skill sets rather than replacing human workers. Navigating these transitions responsibly is vital to minimize potential socio-economic disruptions.\\r\\n\\r\\nFurthermore, the agent AI focuses on learning collaboration policy in simulation and there is some risk if directly applying the policy to the real world due to the distribution shift. Robust testing and continual safety monitoring mechanisms should be put in place to minimize risks of unpredictable behaviors in real-world scenarios. Our “VideoAnalytica\" dataset is collected from the Internet and considering which is not a fully representative source, so we already go through-ed the ethical review and legal process from both Microsoft and University Washington. Be that as it may, we also need to understand biases that might exist in this corpus. Data distributions can be characterized in many ways.', mimetype='text/plain', start_char_idx=0, end_char_idx=2736, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}'), TextNode(id_='612430ac-db61-464b-ab87-499b94a6022f', embedding=None, metadata={'file_path': 'docs\\\\another_example.txt', 'file_name': 'another_example.txt', 'file_type': 'text/plain', 'file_size': 3355, 'creation_date': '2025-07-21', 'last_modified_date': '2025-07-19'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={<NodeRelationship.SOURCE: '1'>: RelatedNodeInfo(node_id='5b853f0a-2fd0-4a35-a2e2-033f53e0acf6', node_type=<ObjectType.DOCUMENT: '4'>, metadata={'file_path': 'docs\\\\another_example.txt', 'file_name': 'another_example.txt', 'file_type': 'text/plain', 'file_size': 3355, 'creation_date': '2025-07-21', 'last_modified_date': '2025-07-19'}, hash='e21b18d7025601f845c7287c1f5cfc20cbd20d88aabe3050302d7a9742561127'), <NodeRelationship.PREVIOUS: '2'>: RelatedNodeInfo(node_id='516c5101-798f-41e1-9332-fe8e96ca6383', node_type=<ObjectType.TEXT: '1'>, metadata={'file_path': 'docs\\\\another_example.txt', 'file_name': 'another_example.txt', 'file_type': 'text/plain', 'file_size': 3355, 'creation_date': '2025-07-21', 'last_modified_date': '2025-07-19'}, hash='e344cdc8a0d9593e40af74747efdf620d95cdc6a1888c23228a1fe2644e00aca')}, metadata_template='{key}: {value}', metadata_separator='\\n', text='2) In the gaming industry, AI agents could transform the role of developers, shifting their focus from scripting non-player characters to refining agent learning processes. Similarly, adaptive robotic systems could redefine manufacturing roles, necessitating new skill sets rather than replacing human workers. Navigating these transitions responsibly is vital to minimize potential socio-economic disruptions.\\r\\n\\r\\nFurthermore, the agent AI focuses on learning collaboration policy in simulation and there is some risk if directly applying the policy to the real world due to the distribution shift. Robust testing and continual safety monitoring mechanisms should be put in place to minimize risks of unpredictable behaviors in real-world scenarios. Our “VideoAnalytica\" dataset is collected from the Internet and considering which is not a fully representative source, so we already go through-ed the ethical review and legal process from both Microsoft and University Washington. Be that as it may, we also need to understand biases that might exist in this corpus. Data distributions can be characterized in many ways. In this workshop, we have captured how the agent level distribution in our dataset is different from other existing datasets. However, there is much more than could be included in a single dataset or workshop. We would argue that there is a need for more approaches or discussion linked to real tasks or topics and that by making these data or system available.\\r\\n\\r\\nWe will dedicate a segment of our project to discussing these ethical issues, exploring potential mitigation strategies, and deploying a responsible multi-modal AI agent. We hope to help more researchers answer these questions together via this paper.', mimetype='text/plain', start_char_idx=1615, end_char_idx=3353, metadata_seperator='\\n', text_template='{metadata_str}\\n\\n{content}')]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from llama_index.core import SimpleDirectoryReader,Document\n",
    "documents = SimpleDirectoryReader(input_files=['./docs/another_example.txt']).load_data()\n",
    "from llama_index.core.node_parser import SentenceSplitter\n",
    "transformations = [SentenceSplitter(chunk_size = 512)]\n",
    "\n",
    "from llama_index.core.ingestion.pipeline import run_transformations\n",
    "nodes = run_transformations(documents, transformations=transformations)\n",
    "index.insert_nodes(nodes)\n",
    "print(nodes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e0ca89",
   "metadata": {},
   "source": [
    "### 4.3 Updating Existing Content: No Direct Edit, Only Replace\n",
    "\n",
    "As for modifying existing content, `LlamaIndex` does not currently support direct node editing.\n",
    "To make changes to an existing node, the recommended approach is:\n",
    "\n",
    "1. Delete the old node using its node ID: ```index.docstore.delete_document('<your_node_id>')```\n",
    "2. Create a new `TextNode` with updated content or metadata.\n",
    "3. Insert ```index.insert_nodes([your_new_node])```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
